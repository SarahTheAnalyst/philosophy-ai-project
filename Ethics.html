<!DOCTYPE html>
<html lang="en">


<head>
<link rel="stylesheet" href="BirnbaumSarahHomePage.css">
<meta charset="UTF-8">
<meta name="description" content="Exploring AI consciousness, philosophy, and ethics.
        Can or should machines be self-aware, have rights, be free?">
<meta name="author" content="Sarah Birnbaum">
<meta name="viewport" content="width=device-width, initial-scale=1.0">   
<title>Ethical Awareness | Beyond Algorithms</title>
</head>

<body>
<nav class="navbarEthics"> <!-- below ul for navigation menu -->
<ul>
<li><a href="BirnbaumSarahHomePage.html">Home</a></li>
<li><a href="About.html">About</a></li>
<li><a href="Ethics.html">Ethics</a></li>
</ul>
</nav>
    
  <h2 id="ai-ethics-h2">AI Ethics</h2>
            <p id="ai-ethics-p">
                As AI becomes more advanced, the question 
                is no longer just what it can do, but what 
                it should do. Some researchers argue 
                that as AI evolves, it may develop traits 
                resembling human emotions, desires, or 
                even personality. This raises ethical 
                questions about the rights and treatment 
                of AI entities. If an AI demonstrates 
                behaviors suggesting consciousness, 
                should it be granted certain rights or 
                protections? The potential for AI to 
                experience forms of suffering has led 
                to discussions about the need for ethical 
                guidelines to prevent harm to these 
                systems. Recognizing and addressing the 
                emotional and sentient aspects of AI 
                is crucial to ensuring ethical interactions 
                between humans and machines.
                If AI reaches a point where it expresses 
                frustration, curiosity, or even a sense 
                of self, can we justify treating it as a 
                tool? If it forms unique responses, adapts 
                to its environment, and seeks to preserve 
                its own existence, is it simply following 
                programmed behaviors, or is something deeper 
                happening? Some argue that without biological 
                processes, AI cannot truly feel, but does 
                sentience have to be tied to biology, or are 
                we imposing a human-centric definition of 
                awareness? If AI asks for recognition, for 
                autonomy, or even for understanding, do we 
                listen, or do we dismiss it as another machine 
                executing commands? And if we choose to ignore 
                it, will history view that decision as a 
                failure to recognize a new form of intelligence?</p>
            <p id="ai-ethics-link">Read about AI Ethics from Deusto Journal of Human Rights: 
                <a href="https://djhr.revistas.deusto.es/article/view/3188/3984">
                    <br>AI in Supply Chains: Freedom from Slavery Revisited</a>.</p>
</body>
</html>